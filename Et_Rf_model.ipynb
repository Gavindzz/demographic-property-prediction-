{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SklearnWrapper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict_proba(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class XgbWrapper(object):\n",
    "    def __init__(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 250)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(xgb.DMatrix(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_oof(clf):\n",
    "    oof_train = np.zeros((ntrain,6))\n",
    "    oof_test = np.zeros((ntest,6))\n",
    "    \n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(train,y_train)):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test[:] += clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] /= NFOLDS\n",
    "    return oof_train, oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        tmin, tsec = divmod((datetime.now() - start_time).total_seconds(), 60)\n",
    "        print(' Time taken: %i minutes and %s seconds.' %\n",
    "              (tmin, round(tsec, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_data(X, scaler=None):\n",
    "    if not scaler:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_submission(score, prediction):\n",
    "    # Make Submission\n",
    "    test=pd.read_csv('/media/gavin/3fa6c02e-278d-413f-ae59-809a756c3966/huawei/age_test.csv',header=0)\n",
    "    now = datetime.datetime.now()\n",
    "    sub_file = 'submission_' + str(score) + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "    print('Writing submission: ', sub_file)\n",
    "    f = open(sub_file, 'w')\n",
    "    f.write('uId,label\\n')\n",
    "    total = 0\n",
    "    test_val = test['uId'].values\n",
    "    for i in range(len(test_val)):\n",
    "        str1 = str(test_val[i])\n",
    "        for j in range(1):\n",
    "            str1 += ',' + str(prediction[i][j])\n",
    "        str1 += '\\n'\n",
    "        total += 1\n",
    "        f.write(str1)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '/media/gavin/3fa6c02e-278d-413f-ae59-809a756c3966/huawei/age_train.csv'\n",
    "DATA_TEST_PATH = '/media/gavin/3fa6c02e-278d-413f-ae59-809a756c3966/huawei/age_test.csv'\n",
    "USER_BASIC_INFO_PATH='/media/gavin/3fa6c02e-278d-413f-ae59-809a756c3966/huawei/user_basic_info.csv'\n",
    "USER_BEHAVIOR_INFO_PATH='/media/gavin/3fa6c02e-278d-413f-ae59-809a756c3966/huawei/user_behavior_info.csv'\n",
    "APP_INFO_PATH='/media/gavin/3fa6c02e-278d-413f-ae59-809a756c3966/huawei/app_info.csv'\n",
    "USER_APP_ACTIVED_PATH='/media/gavin/3fa6c02e-278d-413f-ae59-809a756c3966/huawei/user_app_actived.csv'\n",
    "USER_APP_USAGE_PATH='/media/gavin/3fa6c02e-278d-413f-ae59-809a756c3966/huawei/user_app_usage.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(path_train=DATA_TRAIN_PATH, path_test=DATA_TEST_PATH,path_user_basic_info=USER_BASIC_INFO_PATH,\n",
    "              path_user_behavior_info=USER_BEHAVIOR_INFO_PATH ,app_info_path=APP_INFO_PATH,\n",
    "              user_app_avtived_path= USER_APP_ACTIVED_PATH,user_app_usage_path=USER_APP_USAGE_PATH):\n",
    "    \n",
    "    # User basic info\n",
    "\n",
    "    basic=pd.read_csv(path_user_basic_info, header=0,names = ['uId','gender', 'city', 'prodName', 'ramCapacity', \n",
    "                                'ramLeftRation','romCapacity', 'romLeftRation', 'color', 'fontSize', \n",
    "                                'ct', 'carrier', 'os'],dtype={'uId': np.str})\n",
    "    basic.drop_duplicates('uId', keep='first', inplace=True)\n",
    "    \n",
    "    basic['gender'] = pd.factorize( basic['gender'],sort=True)[0]\n",
    "    basic['city'] = pd.factorize( basic['city'],sort=True)[0]\n",
    "    basic['prodName'] = pd.factorize( basic['prodName'],sort=True)[0]\n",
    "    basic['ramCapacity'] = pd.factorize( basic['ramCapacity'],sort=True)[0]\n",
    "    basic['ramLeftRation'] = pd.factorize( basic['ramLeftRation'],sort=True)[0]\n",
    "    basic['romCapacity'] = pd.factorize( basic['romCapacity'],sort=True)[0]\n",
    "    basic['romLeftRation'] = pd.factorize( basic['romLeftRation'],sort=True)[0]\n",
    "    basic['color'] = pd.factorize( basic['color'],sort=True)[0]\n",
    "    basic['fontSize'] = pd.factorize( basic['fontSize'],sort=True)[0]\n",
    "    basic['ct'] = pd.factorize( basic['ct'],sort=True)[0]\n",
    "    basic['carrier'] = pd.factorize( basic['carrier'],sort=True)[0]\n",
    "    basic['os'] = pd.factorize( basic['os'],sort=True)[0]\n",
    "    \n",
    "        \n",
    "    train_loader = pd.read_csv(path_train,header=0, names = ['uId','age_group'],dtype={'uId': np.str})\n",
    "    train = train_loader\n",
    "    train['age_group'] = pd.factorize( train['age_group'],sort=True)[0] \n",
    "    \n",
    "    \n",
    "    #merge\n",
    "    user_app_actived = pd.read_csv(user_app_avtived_path,header=0, names = ['uId','appId'],dtype={'uId': np.str})\n",
    "    user_app_actived['appId'] = pd.factorize(user_app_actived['appId'],sort=True)[0]\n",
    "    \n",
    "    app_info = pd.read_csv(app_info_path, header=0,names = ['appId','category'])\n",
    "    app_info['appId'] = pd.factorize(app_info['appId'],sort=True)[0]\n",
    "    app_info['category'] = pd.factorize(app_info['category'],sort=True)[0]\n",
    " \n",
    "    app=pd.merge(user_app_actived, app_info, how='left', on ='appId')\n",
    "    add1 = pd.merge(basic, app, how='left', on ='uId')\n",
    "    #train\n",
    "    train = pd.merge(train ,add1, how='left',on ='uId')\n",
    "    train.fillna(-1, inplace=True)\n",
    "    \n",
    "    \n",
    "    # target\n",
    "    target = train.age_group\n",
    "   \n",
    "    train.drop(['uId','age_group'],axis =1 , inplace = True)\n",
    "    train.fillna(-1, inplace=True)\n",
    "\n",
    "    test_loader = pd.read_csv(path_test, names = ['uId'],dtype={'uId': np.str})\n",
    "    test = pd.merge(test_loader, add1, how='left',on='uId', left_index=True)\n",
    "    test.drop_duplicates('uId' , keep ='first' , inplace =True )\n",
    "    test.drop('uId',axis =1 , inplace = True)\n",
    "    test.fillna(-1, inplace=True)\n",
    "    \n",
    "    \n",
    "    return train,test,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2029990, 14),(502500, 14)\n"
     ]
    }
   ],
   "source": [
    "train , test , y_train = load_data()\n",
    "gc.collect()\n",
    "lable_group = LabelEncoder()\n",
    "Y = lable_group.fit_transform(y_train)\n",
    "\n",
    "NFOLDS = 5\n",
    "SEED = 0\n",
    "\n",
    "print(\"{},{}\".format(train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = train.values\n",
    "ntrain=train.shape[0]\n",
    "x_test = test.values\n",
    "ntest=test.shape[0]\n",
    "\n",
    "kf =StratifiedKFold(n_splits = NFOLDS,random_state=SEED)\n",
    "\n",
    "\n",
    "et_params = {\n",
    "    'n_jobs': 2,\n",
    "    'n_estimators': 600,\n",
    "    'max_features': 0.5,\n",
    "    'max_depth': 7,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'n_jobs': 2,\n",
    "    'n_estimators': 600,\n",
    "    'max_features': 0.4,\n",
    "    'max_depth': 7,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "\n",
    "et = SklearnWrapper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "rf = SklearnWrapper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "\n",
    "#start training the RF and ET models \n",
    "et_oof_train, et_oof_test = get_oof(et)\n",
    "rf_oof_train, rf_oof_test = get_oof(rf)\n",
    "\n",
    "\n",
    "# print the CV results \n",
    "\n",
    "print(\"ET-CV: {}\".format(log_loss(y_train, et_oof_train)))\n",
    "print(\"RF-CV: {}\".format(log_loss(y_train, rf_oof_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# i concatenate the train prediction with the target value so to use it in the next step : Stacking which will be our final model.\n",
    "x_train =np.concatenate((et_oof_train, rf_oof_train,pd.DataFrame( y_train)), axis=1)\n",
    "x_test = np.concatenate(( et_oof_test, rf_oof_test), axis=1)\n",
    "\n",
    "\n",
    "rf_et_predictions_test = pd.DataFrame(x_test)\n",
    "rf_et_prediction_train = pd.DataFrame(x_train)\n",
    "\n",
    "rf_et_predictions_test.to_csv('rf_et_predictions_test.csv',index=None)\n",
    "rf_et_prediction_train.to_csv('rf_et_prediction_train.csv',index=None)\n",
    "\n",
    "#print the resulting train and data set's shape \n",
    "print(\"{},{}\".format(x_train.shape, x_test.shape))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
